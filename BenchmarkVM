# Importando as bibliotecas necessárias
import libvirt
import csv
import datetime as dt
import time
import tkinter as tk
from tkinter import ttk

# Criando janela principal Tkinter
root = tk.Tk()
root.title("Benchmark")

# Nomes das VMs que serão monitoradas
vm_names = ["java11", "java8"]

# Tempo de medição em segundos
measurement_time = 5

# Intervalo de medição em segundos
measurement_interval = 2

# Função para escrever os dados em um arquivo CSV
def write_csv(filename, headers, rows):
    try:
        with open(filename, 'w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(headers)
            writer.writerows(rows)
    except Exception as e:
        print(f'Erro ao escrever arquivo {filename}: {e}')
        exit(1)

# Função para coletar as estatísticas de uma VM
def gather_vm_stats(conn, vm):
    stats_cpu = vm.getCPUStats(True)
    stats_mem = vm.memoryStats()
    return {
        "VM": vm.name(), # Nome da VM sendo monitorada
        "Horário de Medição": dt.datetime.now().strftime("%H:%M:%S"), # Data e hora do momento da medição
        "Tempo de CPU (ns)": stats_cpu[0]['cpu_time'], # Tempo total de CPU usado pela VM (em nanosegundos)
        "Tempo de Sistema (ns)": stats_cpu[0]['system_time'], # Tempo total do sistema usado pela VM (em nanosegundos)
        "Tempo de Usuário (ns)": stats_cpu[0]['user_time'], # Tempo total de usuário usado pela VM (em nanosegundos)
        "Memória Alocada (B)": stats_mem.get("actual"), # Quantidade de memória alocada (em bytes)
        "Memória Não Utilizada (B)": stats_mem.get("unused"), # Quantidade de memória não utilizada (em bytes)
        "Memória Disponível (B)": stats_mem.get("available"), # Quantidade de memória disponível (em bytes)
        "Memória Usável (B)": stats_mem.get("usable"), # Quantidade de memória usável (em bytes)
        "Caches de Disco (B)": stats_mem.get("disk_caches", 0) # Quantidade de caches de disco usados (em bytes)
    }

# Abre conexão com qemu:///system e armazena as VMs
# Define as colunas do cabeçalho da tabela CSV e inicializa a lista de linhas vazia
def start_benchmark():
    # Abre conexão com qemu:///system
    try:
        conn = libvirt.open('qemu:///system')
    except libvirt.libvirtError as e:
        print(f'Erro ao abrir conexão com qemu:///system: {e}')
        exit(1)

    # Armazena as VMs
    vms = []
    for name in vm_names:
        vm = conn.lookupByName(name)
        if not vm:
            print(f'Falha ao encontrar a VM {name}')
            exit(1)
        vms.append(vm)

    # Define as colunas do cabeçalho da tabela CSV
    headers = list(gather_vm_stats(conn, vms[0]).keys())

    # Inicializa a lista de linhas vazia
    rows = []

    # Cria a barra de progresso
    progress_bar = ttk.Progressbar(root, length=200, mode='determinate')
    progress_bar.pack(pady=10)

    # Adiciona um botão para interromper o benchmark
    stop_button = ttk.Button(root, text="Parar Benchmark", command=root.quit)
    stop_button.pack(pady=10)

    # Executa o benchmark por um tempo específico com intervalos regulares
    try:
        end_time = time.time() + measurement_time
        measurement_count = 0
        while time.time() < end_time:
            for vm in vms:
                rows.append(gather_vm_stats(conn, vm))
                measurement_count += 1
                progress_bar['value'] = measurement_count / (measurement_time / measurement_interval) * 100
                root.update_idletasks() # atualiza a interface gráfica
                time.sleep(measurement_interval)

            # Escreve os dados coletados em um arquivo CSV
            write_csv("benchmark.csv", headers, [list(row.values()) for row in rows])

    except libvirt.libvirtError as e:
        print(f'Erro ao conectar com o hypervisor: {e}')
        exit(1)

    except Exception as e:
        print(f'Ocorreu um erro: {e}')
        exit(1)

    finally:
        # Fecha a conexão com libvirt e encerra o programa
        conn.close()
        print("Benchmark concluído com sucesso!")
        root.quit()

# Chama a função para iniciar o benchmark
start_benchmark()

